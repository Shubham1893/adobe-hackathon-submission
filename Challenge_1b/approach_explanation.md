# Technical Approach: Persona-Driven Document Intelligence

## 1. Executive Summary

This project addresses the core challenge of "Connecting the Dots": transforming static PDFs into an intelligent, responsive experience. Our solution is an offline-first, on-device semantic search pipeline engineered to analyze a collection of documents and rank their internal sections based on a user's specific persona and task. We solve the problem of understanding user intent within a highly constrained environment (CPU-only, â‰¤1GB model, no network access) by leveraging a lightweight but powerful sentence-embedding model to bridge the gap between user queries and document content.

## 2. System Architecture and Design Principles

Our system was built on three core principles to ensure compliance and robustness:

* **Modular, Two-Stage Architecture:** The solution is decoupled into two distinct stages. The `Challenge_1a` extractor acts as a high-speed pre-processing module, providing clean, structured input (document outlines) to the `Challenge_1b` intelligence core. This separation of concerns makes the system more maintainable and efficient.

* **Offline-First and Self-Contained:** The entire pipeline is designed for zero network dependency. The AI model is built directly into the Docker image, ensuring the solution is fully portable and works reliably in the isolated judging environment.

* **Performance by Design:** Every technical choice was driven by the strict CPU, memory, and time constraints. We selected `PyMuPDF` for its best-in-class parsing speed and the `all-MiniLM-L6-v2` model for its optimal balance of semantic performance and small resource footprint (~80MB).

## 3. Core Methodology: A Step-by-Step Breakdown

Our semantic analysis pipeline transforms user intent into a ranked list of relevant document sections.

**A. Foundational Content Chunking:** We first leverage the JSON outlines generated by the `Challenge_1a` module. Using these structural markers, we segment each PDF into logical, coherent sections based on its actual headings. This provides superior contextual integrity compared to naive methods like fixed-size chunking or page-level splitting, leading to more accurate downstream analysis.

**B. Dynamic Query Vectorization:** The user's `persona` and `job-to-be-done` are combined into a single, rich query. This query is then transformed by the Sentence-Transformer model into a 384-dimensional vector embedding that numerically represents the user's core intent.

**C. Semantic Indexing of Documents:** In parallel, every text section extracted from the document collection is passed through the same model to create a corresponding vector embedding. This process creates a searchable "semantic index" of the entire document library in memory.

**D. High-Speed Relevance Ranking:** We use **Cosine Similarity** to calculate the semantic proximity between the user's query vector and every section vector in our index. This metric is computationally efficient and highly effective at measuring similarity in high-dimensional space. The resulting scores, which range from -1 to 1, represent the relevance of each section to the user's task. All sections are then ranked in descending order of this score.

## 4. Conclusion

This solution is a robust, efficient, and scalable system that successfully connects user intent with document content in a constrained, offline environment. It fully complies with all hackathon rules and provides a powerful foundation for a new generation of intelligent document experiences.
